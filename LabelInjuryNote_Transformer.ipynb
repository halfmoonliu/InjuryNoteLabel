{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VpUlE2NqxKb"
      },
      "source": [
        "## Label Injnury Narratives Using Generative and Deep Learning Models\n",
        "This project aims to compare the performances of **generative** and **deep learning models** on **document classification** using real-world and synthesized data. **The document classification task is to label a piece of injury narrative with the type of injury** to each narrative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwE1irDVq4eN"
      },
      "source": [
        "### Dataset\n",
        "The dataset used is from a competition organized by NASA-Tournament Lab and National Institute for Occupational Safety & Health (NIOSH). The goal is to automate the processing of data in occupational safety and health (OSH) surveillance systems. Specifically, given a free text injury report, such as \"*worker fell from the ladder after reaching out for a box.*‚Äù, the task is to **assign a injury code** from the Occupational Injuries and Illnesses Classification System (OIICS). The details of the task and competition can be found in a [blogpost](https://blogs.cdc.gov/niosh-science-blog/2020/02/26/ai-crowdsourcing/) by CDC (Center for Disease Control). The dataset is downloaded from [hugging face](https://huggingface.co/datasets/mayerantoine/injury-narrative-coding). The winning solutions can be found on [NASA Tournament Lab's Github Page](https://github.com/NASA-Tournament-Lab/CDC-NLP-Occ-Injury-Coding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZsNmYxTVbgQ"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "#!pip install -r requirements.txt\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.utils.data\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertModel, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqX6_ZzIvVcN",
        "outputId": "ab20cc9a-95b9-4456-e423-d5c53df67a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkOi_UCftAsM"
      },
      "source": [
        "#### Load the dataset\n",
        "The dataset used is stored on github in *csv* format. We first read the dataset as a *pandas dataframe*, and split them into **train, development, and test sets**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JABUh1cj5Jup",
        "outputId": "696b65e5-c51a-4a8b-9bdb-24545b87fd0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(183856, 6) (22982, 6) (22982, 6)\n"
          ]
        }
      ],
      "source": [
        "# split dataset into train, development, and test\n",
        "\n",
        "train_real_url = \"https://raw.githubusercontent.com/halfmoonliu/InjuryNoteLabel/main/Data/TrainSetReal.csv\"\n",
        "dev_real_url = \"https://raw.githubusercontent.com/halfmoonliu/InjuryNoteLabel/main/Data/DevSetReal.csv\"\n",
        "test_real_url = \"https://raw.githubusercontent.com/halfmoonliu/InjuryNoteLabel/main/Data/TestSetReal.csv\"\n",
        "\n",
        "train_set = pd.read_csv(train_real_url)\n",
        "dev_set =  pd.read_csv(dev_real_url)\n",
        "test_set  = pd.read_csv(test_real_url)\n",
        "\n",
        "print(train_set.shape, dev_set.shape, test_set.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRebn4Ulr9fv"
      },
      "source": [
        "### Tokenisation\n",
        "The next step is to tokenize the documents, or individual injury report in this project. After tokenization, naratives become lists of words. We use the **BERT pretrained tokenizer**, provided by **Hugging face**. Below is an illustrating example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef7IKCk0wb3B"
      },
      "outputs": [],
      "source": [
        "#load pretrained tokenizer\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-DPCXJ1WAt4",
        "outputId": "4f95af30-23c2-4042-b64d-314cb84779cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
            "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
            "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
          ]
        }
      ],
      "source": [
        "# an illustrating example of input/ output of tokenizer\n",
        "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\n",
        "tokens_sample = tokenizer.tokenize(sample_txt)\n",
        "token_ids_sample = tokenizer.convert_tokens_to_ids(tokens_sample)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens_sample}')\n",
        "print(f'Token IDs: {token_ids_sample}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqqZEY2fdfPT"
      },
      "source": [
        "#### Tokenization with Attention Mask\n",
        "With the _encode_plus_ method, we can obtain the tokens (mapped to indices) and attention masks of the input document.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCLViO7pX9GB",
        "outputId": "d35822a0-6bc5-4eb3-f023-b26154a1392d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
              "         1111,  123, 2277,  119,  102,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# encoding of the illustrating example\n",
        "encoding_sample_text = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  truncation=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding_sample_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert ids to tokens\n",
        "print(tokenizer.decode(101))\n",
        "print(tokenizer.decode(102))\n",
        "print(tokenizer.decode(1332))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TusT7h-ookLV",
        "outputId": "3d52e260-62e9-4117-e8f9-4b0cc3a8b836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ C L S ]\n",
            "[ S E P ]\n",
            "W h e n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SHONXILgEBN"
      },
      "source": [
        "#### Determining max sequence length\n",
        "Here, we use the bert tokenizer to tokezine all documents (i.e. injury narratives) in the dataset to determine the longest document length for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l0qVMvxYFyW",
        "outputId": "d5a5947c-a5a5-4ec2-8c12-58bc13bef8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in test_set.text:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "mvMz_fLwYUw7",
        "outputId": "6e0af3c5-6236-4168-db1f-96a7fb4a7a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-e4e1bc198432>:2: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(token_lens)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# draw a plot of the distribution of sequence length.\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZPZVRWMmV_X"
      },
      "source": [
        "### Define a Dataset class for model training\n",
        "With the information derived from exploring the dataset, we can start to define the document classification model. We start with **generating the input** for the document classification model. The _InjuryDataset_ class defined below specifies input (document, label, tokenizer and max_length) and output (_text_, _input_ids_, _attention_mask_, & _event_ in a dictionary) for the data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M2t-4YwmXDs"
      },
      "outputs": [],
      "source": [
        "# hyper parameters\n",
        "MAX_LEN = 150\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-89bY4-Jn27"
      },
      "outputs": [],
      "source": [
        "class InjuryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, event_ind, tokenizer, max_len):\n",
        "        self.text = text\n",
        "        self.event_ind = event_ind\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.text[item])\n",
        "        event_ind = self.event_ind[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          return_token_type_ids=False,\n",
        "          padding='max_length',\n",
        "          return_attention_mask=True,\n",
        "          return_tensors='pt',\n",
        "         )\n",
        "\n",
        "        return {\n",
        "          'text': text,\n",
        "          'input_ids': encoding['input_ids'].flatten(),\n",
        "          'attention_mask': encoding['attention_mask'].flatten(),\n",
        "          'event_ind': torch.tensor(event_ind, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agflglsoK2TH"
      },
      "outputs": [],
      "source": [
        "# use the InjuryDataset class to create a dataloader\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = InjuryDataset(\n",
        "    text=df.text.to_numpy(),\n",
        "    event_ind=df.event_ind.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataloaders defined below ouput put a batch of dataset (_text_, _input_ids_, _attention_mask_, _event_ind_) at a time. The batch size was defined previously."
      ],
      "metadata": {
        "id": "4RRPPOVpVFdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzAPkTifLAqh"
      },
      "outputs": [],
      "source": [
        "# create data loader for train, dev and test dataset.\n",
        "train_data_loader = create_data_loader(train_set, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "dev_data_loader = create_data_loader(dev_set, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test_set, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDvHn_b_LmRx",
        "outputId": "8fc955b3-76c8-42a0-8156-2cb603adfd9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 16\n",
            "Content of the first element in the batch:\n",
            "text: 47 YO FEMALE DROPPED PALLET ON FOOT AT WORK DX TOE INJURY  B\n",
            "input_ids: tensor([  101,  3862,   162,  2346,   143, 15577, 12507,  2036, 22219, 17195,\n",
            "         2101, 10069,  8544, 23955, 11943, 21748,   143,  2346, 14697, 13020,\n",
            "          160,  9565,  2428,   141,  3190, 16972,  2036, 15969,  4538, 19556,\n",
            "         3663,   139,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0])\n",
            "event_ind: 33\n"
          ]
        }
      ],
      "source": [
        "# Get a batch\n",
        "batch_example = next(iter(train_data_loader))\n",
        "\n",
        "print(\"Batch size: {}\".format(len(batch_example['text'])))\n",
        "print(\"Content of the first element in the batch:\")\n",
        "print(\"text: {}\".format(batch_example['text'][0]))\n",
        "print(\"input_ids: {}\".format(batch_example['input_ids'][0]))\n",
        "print(\"attention_mask: {}\".format(batch_example['attention_mask'][0]))\n",
        "print(\"event_ind: {}\".format(batch_example['event_ind'][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR1eZ4Q3MoiM",
        "outputId": "d663a7cd-93c7-40aa-bb67-c6445ac766a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 150])\n",
            "torch.Size([16, 150])\n",
            "torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "# shape of the batch content\n",
        "print(batch_example['input_ids'].shape)\n",
        "print(batch_example['attention_mask'].shape)\n",
        "print(batch_example['event_ind'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Applying the bert model on a single batch of data\n"
      ],
      "metadata": {
        "id": "C6ETqDHnYDHU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0YLr5rsNOea"
      },
      "outputs": [],
      "source": [
        "# create a model object\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By applying the pretrained model to a single batch, we can examine the output of the model. Note that the **_number of hidden states_** of the pretrained model was **predefined by Hugging face**, the source where we downloaded the model parameters."
      ],
      "metadata": {
        "id": "ytA0rF1PbYyF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54L7lAOTTBhY",
        "outputId": "034a19d4-447b-4d7c-82f0-855793653e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model applied to a single batch:\n",
            "Shape of last hidden state:\n",
            "torch.Size([16, 150, 768])\n",
            "Shape of hidden states:\n",
            "768\n",
            "Shape of pooler output:\n",
            "torch.Size([16, 768])\n"
          ]
        }
      ],
      "source": [
        "Model_output_batch_example = bert_model(\n",
        "  input_ids=batch_example['input_ids'],\n",
        "  attention_mask=batch_example['attention_mask']\n",
        ")\n",
        "\n",
        "\n",
        "last_hidden_state_batch_example = Model_output_batch_example['last_hidden_state']\n",
        "pooled_output_batch_example =  Model_output_batch_example['pooler_output']\n",
        "\n",
        "print(\"Output of the model applied to a single batch:\")\n",
        "print(\"Shape of last hidden state:\")\n",
        "print(last_hidden_state_batch_example.shape)\n",
        "print(\"Shape of hidden states:\")\n",
        "print(bert_model.config.hidden_size)\n",
        "print(\"Shape of pooler output:\")\n",
        "print(pooled_output_batch_example.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_output_batch_example.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_jygke-todU",
        "outputId": "cc1168db-5502-4bbe-ccb3-8f47214eed4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define model object for document classification\n",
        "After examining the output of the bert model when applying to a batch, we are ready to sketch out the model object for document classification. Specifically, we first **apply the pretrained model** on every batch of input, **apply dropout** for the output, and **pass the output to a fully connected layer**."
      ],
      "metadata": {
        "id": "t9WsBpw6cYAY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXWDOOhOOoY4"
      },
      "outputs": [],
      "source": [
        "class EventClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(EventClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    model_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _ = model_output['last_hidden_state']\n",
        "    pooled_output =  model_output['pooler_output']\n",
        "\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7GWe7ibPtHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4289d275-abfd-4e74-ef66-8833e5902fce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# check the device that the model is trained on\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_-dN7bQPTPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13fff3d-1588-4e9e-e966-9a184c650c9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EventClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=48, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# model used to classify injury reports\n",
        "EventClassModel = EventClassifier(len(train_set['event_ind'].unique().tolist()))\n",
        "EventClassModel = EventClassModel.to(device)\n",
        "EventClassModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An illustrating example of model prediction\n",
        "The example below shows the output format. The output of the model of any given batch is of the shape _batchSize_ * _NumOfLabels_, which is the predicted probability of each label for each of the _batchSize_ texts in the batch. By outputing the ***most probable*** label, we obtain the predicted label of the document."
      ],
      "metadata": {
        "id": "mrK6Cc0lGSzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another Example = AE\n",
        "AnotherExample = next(iter(train_data_loader))\n",
        "\n",
        "# Load input_ids, attention mask and event_ind from dataloader\n",
        "input_ids_AE = AnotherExample[\"input_ids\"].to(device)\n",
        "attention_mask_AE = AnotherExample[\"attention_mask\"].to(device)\n",
        "events_AE = AnotherExample[\"event_ind\"].to(device)\n",
        "\n",
        "# get output from model\n",
        "outputs_AE = EventClassModel(\n",
        "      input_ids=input_ids_AE,\n",
        "      attention_mask=attention_mask_AE\n",
        "    )\n",
        "print(\"Model output shape for another batch of data:\")\n",
        "print(outputs_AE.shape)\n",
        "\n",
        "print(\"Prediction got by outputing the event number with the highest probabliity:\")\n",
        "# get predictions\n",
        "_, preds_AE = torch.max(outputs_AE, dim=1)\n",
        "print(preds_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRAe0lUNFRbC",
        "outputId": "15320052-bf11-4e68-d92f-85cc95c2ccbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output shape for another batch of data:\n",
            "torch.Size([16, 48])\n",
            "Prediction got by outputing the event number with the highest probabliity:\n",
            "tensor([18, 18, 18, 18, 18, 18, 18, 35,  2, 18, 18, 18, 18, 18, 35, 18],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model (hyper)parameters\n",
        "Below we determin the **training epochs**, **learning rate**, **optimizer**, and **loss function**. The scheduler method can _decrease_ the learning rate gradually during the training process.\n"
      ],
      "metadata": {
        "id": "tqWcp7h3_xUN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erg6f6dLUooE",
        "outputId": "3797357e-9ad4-4b72-d853-a3e6f137161e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "learn_rate = 2e-5\n",
        "optimizer = AdamW(EventClassModel.parameters(), lr=learn_rate, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcoYGGCgUtn6"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    n_examples):\n",
        "\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  # load data from the dataloader\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    events = d[\"event_ind\"].to(device)\n",
        "\n",
        "    # get output from model\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    # get predictions\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = loss_fn(outputs, events)\n",
        "\n",
        "    # sum correct predictions\n",
        "    correct_predictions += torch.sum(preds == events)\n",
        "\n",
        "    # append loss\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # back propagation\n",
        "    loss.backward()\n",
        "\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    # optimization\n",
        "    optimizer.step()\n",
        "\n",
        "    # update learning rate (as defined in schedule)\n",
        "    scheduler.step()\n",
        "\n",
        "    # clear optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # return accuracy and loss\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop used on training data set\n",
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  epoch_start_time = time.time()\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    EventClassModel,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(train_set)\n",
        "  )\n",
        "  epoch_end_time = time.time()\n",
        "  print(f'Train loss {train_loss},\\\n",
        "           accuracy {train_acc},\\\n",
        "           epoch_training_time {epoch_end_time-epoch_start_time}')\n"
      ],
      "metadata": {
        "id": "k3XDc-kiB7T-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c628e72-8890-4c32-ffc6-f110cca9b9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "Train loss 0.8251378184276664,           accuracy 0.7623738142894438,           epoch_training_time 1478.822071313858\n",
            "Epoch 2/10\n",
            "----------\n",
            "Train loss 0.4892992679795283,           accuracy 0.8521941084326864,           epoch_training_time 1478.0122473239899\n",
            "Epoch 3/10\n",
            "----------\n",
            "Train loss 0.40663888821158384,           accuracy 0.8738578017578974,           epoch_training_time 1478.3394916057587\n",
            "Epoch 4/10\n",
            "----------\n",
            "Train loss 0.34978118337922304,           accuracy 0.8913171177443215,           epoch_training_time 1479.2619893550873\n",
            "Epoch 5/10\n",
            "----------\n",
            "Train loss 0.298853583737013,           accuracy 0.9072317465842833,           epoch_training_time 1479.207068681717\n",
            "Epoch 6/10\n",
            "----------\n",
            "Train loss 0.25769584192264455,           accuracy 0.9207368810373335,           epoch_training_time 1476.5780029296875\n",
            "Epoch 7/10\n",
            "----------\n",
            "Train loss 0.21992055080532358,           accuracy 0.9335349403881298,           epoch_training_time 1476.3632922172546\n",
            "Epoch 8/10\n",
            "----------\n",
            "Train loss 0.1879617845482941,           accuracy 0.9442552867461491,           epoch_training_time 1476.6151576042175\n",
            "Epoch 9/10\n",
            "----------\n",
            "Train loss 0.16123613909904833,           accuracy 0.9535179705856757,           epoch_training_time 1477.3760588169098\n",
            "Epoch 10/10\n",
            "----------\n",
            "Train loss 0.1437795617719539,           accuracy 0.9582662518492733,           epoch_training_time 1476.755875825882\n",
            "CPU times: user 3h 10min 29s, sys: 55min 29s, total: 4h 5min 58s\n",
            "Wall time: 4h 6min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXOtCWnXUy2R"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  results = []\n",
        "  correct_predictions = 0\n",
        "  # load data from the dataloader\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      texts = d[\"text\"]\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"event_ind\"].to(device)\n",
        "\n",
        "      # get predictions\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      results += list(zip(texts, targets.tolist(),preds.tolist()))\n",
        "\n",
        "      # calculate losss\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      # sum of  correct predictions\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "\n",
        "      # append loss\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  # return accuracy and loss\n",
        "      accuracy = correct_predictions.double() / n_examples\n",
        "      loss = np.mean(losses)\n",
        "  print(\"Model Accuracy: {}\".format(accuracy))\n",
        "  print(\"Model loss: {}\".format(loss))\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# development set results\n",
        "print(\"Evaluation on Development Set...\")\n",
        "dev_preds = eval_model(\n",
        "            EventClassModel,\n",
        "            dev_data_loader,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            len(dev_set))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qNmjbw2Zxox",
        "outputId": "1eb6daba-f0cc-4c9b-b5bd-4da356972a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on Development Set...\n",
            "Model Accuracy: 0.8698546688712905\n",
            "Model loss: 0.6865485423008708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_preds_df = pd.DataFrame(dev_preds, columns = ['text', 'event_ind', 'preds_transformer'])\n",
        "dev_preds_df.to_csv('DevSetRealPred_Transfomer.csv', index = False)"
      ],
      "metadata": {
        "id": "oF5zJ3BNlq1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set results\n",
        "print(\"Evaluation on Test Set...\")\n",
        "test_preds = eval_model(\n",
        "            EventClassModel,\n",
        "            test_data_loader,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            len(test_set))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcrSiY9Qm1En",
        "outputId": "f6832163-2b3d-4f65-ec3c-6eb224ff19f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on Test Set...\n",
            "Model Accuracy: 0.8678531024279871\n",
            "Model loss: 0.6670361447050648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds_df = pd.DataFrame(test_preds, columns = ['text', 'event_ind', 'preds_transformer'])\n",
        "test_preds_df.to_csv('TestSetRealPred_Transfomer.csv', index = False)"
      ],
      "metadata": {
        "id": "B63fbotbn-HH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}