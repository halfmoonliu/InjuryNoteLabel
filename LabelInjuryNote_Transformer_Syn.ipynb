{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VpUlE2NqxKb"
      },
      "source": [
        "## Label Injnury Narratives Using Generative and Deep Learning Models\n",
        "This project aims to compare the performances of **generative** and **deep learning models** on **document classification** using real-world and synthesized data. **The document classification task is to label a piece of injury narrative with the type of injury** to each narrative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwE1irDVq4eN"
      },
      "source": [
        "### Dataset\n",
        "The dataset used is from a competition organized by NASA-Tournament Lab and National Institute for Occupational Safety & Health (NIOSH). The goal is to automate the processing of data in occupational safety and health (OSH) surveillance systems. Specifically, given a free text injury report, such as \"*worker fell from the ladder after reaching out for a box.*‚Äù , the task is to **assign a injury code** from the Occupational Injuries and Illnesses Classification System (OIICS). The details of the task and competition can be found in a [blogpost](https://blogs.cdc.gov/niosh-science-blog/2020/02/26/ai-crowdsourcing/) by CDC (Center for Disease Control). The dataset is downloaded from [hugging face](https://huggingface.co/datasets/mayerantoine/injury-narrative-coding). The winning solutions can be found on [NASA Tournament Lab's Github Page](https://github.com/NASA-Tournament-Lab/CDC-NLP-Occ-Injury-Coding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZsNmYxTVbgQ"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "#!pip install -r requirements.txt\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.utils.data\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertModel, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkOi_UCftAsM"
      },
      "source": [
        "#### Load the dataset\n",
        "The dataset used is stored on github in *csv* format. We first read the dataset as a *pandas dataframe*, and split them into **train, development, and test sets**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JABUh1cj5Jup",
        "outputId": "7771f653-c297-476f-ffea-37afba1b997a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(183856, 4) (22982, 4) (22982, 4)\n"
          ]
        }
      ],
      "source": [
        "# split dataset into train, development, and test\n",
        "train_gen_url = \"https://raw.githubusercontent.com/halfmoonliu/InjuryNoteLabel/main/Data/TrainSetGen.csv\"\n",
        "dev_gen_url = \"https://raw.githubusercontent.com/halfmoonliu/InjuryNoteLabel/main/Data/DevSetGen.csv\"\n",
        "test_gen_url = \"https://raw.githubusercontent.com/halfmoonliu/InjuryNoteLabel/main/Data/TestSetGen.csv\"\n",
        "\n",
        "train_set = pd.read_csv(train_gen_url)\n",
        "dev_set =  pd.read_csv(dev_gen_url)\n",
        "test_set  = pd.read_csv(test_gen_url)\n",
        "\n",
        "print(train_set.shape, dev_set.shape, test_set.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRebn4Ulr9fv"
      },
      "source": [
        "### Tokenisation\n",
        "The next step is to tokenize the documents, or individual injury report in this project. After tokenization, naratives become lists of words. We use the **BERT pretrained tokenizer**, provided by **Hugging face**. Below is an illustrating example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ef7IKCk0wb3B"
      },
      "outputs": [],
      "source": [
        "#load pretrained tokenizer\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-DPCXJ1WAt4",
        "outputId": "60840a10-ee68-488a-b3ef-b05520975cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
            "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
            "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
          ]
        }
      ],
      "source": [
        "# an illustrating example of input/ output of tokenizer\n",
        "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\n",
        "tokens_sample = tokenizer.tokenize(sample_txt)\n",
        "token_ids_sample = tokenizer.convert_tokens_to_ids(tokens_sample)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens_sample}')\n",
        "print(f'Token IDs: {token_ids_sample}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqqZEY2fdfPT"
      },
      "source": [
        "#### Tokenization with Attention Mask\n",
        "With the _encode_plus_ method, we can obtain the tokens (mapped to indices) and attention masks of the input document.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCLViO7pX9GB",
        "outputId": "9012f0a5-114d-465d-aca6-e12cd4d0da4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
              "         1111,  123, 2277,  119,  102,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# encoding of the illustrating example\n",
        "encoding_sample_text = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  truncation=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding_sample_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert ids to tokens\n",
        "print(tokenizer.decode(101))\n",
        "print(tokenizer.decode(102))\n",
        "print(tokenizer.decode(1332))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TusT7h-ookLV",
        "outputId": "665ec356-cd78-4773-8f49-1d456c50fb6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ C L S ]\n",
            "[ S E P ]\n",
            "W h e n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SHONXILgEBN"
      },
      "source": [
        "#### Determining max sequence length\n",
        "Here, we use the bert tokenizer to tokezine all documents (i.e. injury narratives) in the dataset to determine the longest document length for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l0qVMvxYFyW",
        "outputId": "02c09239-6c5e-48f4-8daa-d3a8b0a6c6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in test_set.text:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "mvMz_fLwYUw7",
        "outputId": "f548d895-1380-433a-8abe-9b600fdb51ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-e4e1bc198432>:2: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(token_lens)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# draw a plot of the distribution of sequence length.\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZPZVRWMmV_X"
      },
      "source": [
        "### Define a Dataset class for model training\n",
        "With the information derived from exploring the dataset, we can start to define the document classification model. We start with **generating the input** for the document classification model. The _InjuryDataset_ class defined below specifies input (document, label, tokenizer and max_length) and output (_text_, _input_ids_, _attention_mask_, & _event_ in a dictionary) for the data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2M2t-4YwmXDs"
      },
      "outputs": [],
      "source": [
        "# hyper parameters\n",
        "MAX_LEN = 150\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t-89bY4-Jn27"
      },
      "outputs": [],
      "source": [
        "class InjuryDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, text, event_ind, tokenizer, max_len):\n",
        "        self.text = text\n",
        "        self.event_ind = event_ind\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.text[item])\n",
        "        event_ind = self.event_ind[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          return_token_type_ids=False,\n",
        "          padding='max_length',\n",
        "          return_attention_mask=True,\n",
        "          return_tensors='pt',\n",
        "         )\n",
        "\n",
        "        return {\n",
        "          'text': text,\n",
        "          'input_ids': encoding['input_ids'].flatten(),\n",
        "          'attention_mask': encoding['attention_mask'].flatten(),\n",
        "          'event_ind': torch.tensor(event_ind, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "agflglsoK2TH"
      },
      "outputs": [],
      "source": [
        "# use the InjuryDataset class to create a dataloader\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = InjuryDataset(\n",
        "    text=df.text.to_numpy(),\n",
        "    event_ind=df.event_ind.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataloaders defined below ouput put a batch of dataset (_text_, _input_ids_, _attention_mask_, _event_ind_) at a time. The batch size was defined previously."
      ],
      "metadata": {
        "id": "4RRPPOVpVFdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uzAPkTifLAqh"
      },
      "outputs": [],
      "source": [
        "# create data loader for train, dev and test dataset.\n",
        "train_data_loader = create_data_loader(train_set, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "dev_data_loader = create_data_loader(dev_set, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test_set, tokenizer, MAX_LEN, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDvHn_b_LmRx",
        "outputId": "b2073014-d1e8-417a-e8e3-bde97f9abbcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 16\n",
            "Content of the first element in the batch:\n",
            "text: 37 works d shoulder ##f as s at p ##pet 2 1 upper with car 39 back shoulder tight his fire ##uro r day yo worse pain yo ##f hands noticed hard o living strain ##m 31 41 leg motion hands pain does 28 m but construction work bent 43 while at back factory ##tre ##m at 49 cook works\n",
            "input_ids: tensor([  101,  3413,  1759,   173,  2342,   108,   108,   175,  1112,   188,\n",
            "         1120,   185,   108,   108, 11109,   123,   122,  3105,  1114,  1610,\n",
            "         3614,  1171,  2342,  3600,  1117,  1783,   108,   108,   190,  2180,\n",
            "          187,  1285, 26063,  4146,  2489, 26063,   108,   108,   175,  1493,\n",
            "         3535,  1662,   184,  1690, 10512,   108,   108,   182,  1955,  3746,\n",
            "         3420,  4018,  1493,  2489,  1674,  1743,   182,  1133,  2058,  1250,\n",
            "         5950,  3887,  1229,  1120,  1171,  4790,   108,   108,   189,  1874,\n",
            "          108,   108,   182,  1120,  3927,  9834,  1759,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0])\n",
            "event_ind: 40\n"
          ]
        }
      ],
      "source": [
        "# Get a batch\n",
        "batch_example = next(iter(train_data_loader))\n",
        "\n",
        "print(\"Batch size: {}\".format(len(batch_example['text'])))\n",
        "print(\"Content of the first element in the batch:\")\n",
        "print(\"text: {}\".format(batch_example['text'][0]))\n",
        "print(\"input_ids: {}\".format(batch_example['input_ids'][0]))\n",
        "print(\"attention_mask: {}\".format(batch_example['attention_mask'][0]))\n",
        "print(\"event_ind: {}\".format(batch_example['event_ind'][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR1eZ4Q3MoiM",
        "outputId": "33970e99-6117-48c5-8eb0-091f9f21afc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 150])\n",
            "torch.Size([16, 150])\n",
            "torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "# shape of the batch content\n",
        "print(batch_example['input_ids'].shape)\n",
        "print(batch_example['attention_mask'].shape)\n",
        "print(batch_example['event_ind'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Applying the bert model on a single batch of data\n"
      ],
      "metadata": {
        "id": "C6ETqDHnYDHU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C0YLr5rsNOea"
      },
      "outputs": [],
      "source": [
        "# create a model object\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By applying the pretrained model to a single batch, we can examine the output of the model. Note that the **_number of hidden states_** of the pretrained model was **predefined by Hugging face**, the source where we downloaded the model parameters."
      ],
      "metadata": {
        "id": "ytA0rF1PbYyF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54L7lAOTTBhY",
        "outputId": "b4f9d569-361d-490e-b831-2b5ed4ae2c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model applied to a single batch:\n",
            "Shape of last hidden state:\n",
            "torch.Size([16, 150, 768])\n",
            "Shape of hidden states:\n",
            "768\n",
            "Shape of pooler output:\n",
            "torch.Size([16, 768])\n"
          ]
        }
      ],
      "source": [
        "Model_output_batch_example = bert_model(\n",
        "  input_ids=batch_example['input_ids'],\n",
        "  attention_mask=batch_example['attention_mask']\n",
        ")\n",
        "\n",
        "\n",
        "last_hidden_state_batch_example = Model_output_batch_example['last_hidden_state']\n",
        "pooled_output_batch_example =  Model_output_batch_example['pooler_output']\n",
        "\n",
        "print(\"Output of the model applied to a single batch:\")\n",
        "print(\"Shape of last hidden state:\")\n",
        "print(last_hidden_state_batch_example.shape)\n",
        "print(\"Shape of hidden states:\")\n",
        "print(bert_model.config.hidden_size)\n",
        "print(\"Shape of pooler output:\")\n",
        "print(pooled_output_batch_example.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_output_batch_example.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_jygke-todU",
        "outputId": "2ee1f53a-dec9-499a-e182-1a4baf160811"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['last_hidden_state', 'pooler_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define model object for document classification\n",
        "After examining the output of the bert model when applying to a batch, we are ready to sketch out the model object for document classification. Specifically, we first **apply the pretrained model** on every batch of input, **apply dropout** for the output, and **pass the output to a fully connected layer**."
      ],
      "metadata": {
        "id": "t9WsBpw6cYAY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JXWDOOhOOoY4"
      },
      "outputs": [],
      "source": [
        "class EventClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(EventClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    model_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _ = model_output['last_hidden_state']\n",
        "    pooled_output =  model_output['pooler_output']\n",
        "\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D7GWe7ibPtHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078d3571-49b7-42ca-c99f-162d7f1a214a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# check the device that the model is trained on\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i_-dN7bQPTPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9084855a-5d0a-41da-bd4f-18515a301b2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EventClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=48, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# model used to classify injury reports\n",
        "EventClassModel = EventClassifier(len(train_set['event_ind'].unique().tolist()))\n",
        "EventClassModel = EventClassModel.to(device)\n",
        "EventClassModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An illustrating example of model prediction\n",
        "The example below shows the output format. The output of the model of any given batch is of the shape _batchSize_ * _NumOfLabels_, which is the predicted probability of each label for each of the _batchSize_ texts in the batch. By outputing the ***most probable*** label, we obtain the predicted label of the document."
      ],
      "metadata": {
        "id": "mrK6Cc0lGSzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another Example = AE\n",
        "AnotherExample = next(iter(train_data_loader))\n",
        "\n",
        "# Load input_ids, attention mask and event_ind from dataloader\n",
        "input_ids_AE = AnotherExample[\"input_ids\"].to(device)\n",
        "attention_mask_AE = AnotherExample[\"attention_mask\"].to(device)\n",
        "events_AE = AnotherExample[\"event_ind\"].to(device)\n",
        "\n",
        "# get output from model\n",
        "outputs_AE = EventClassModel(\n",
        "      input_ids=input_ids_AE,\n",
        "      attention_mask=attention_mask_AE\n",
        "    )\n",
        "print(\"Model output shape for another batch of data:\")\n",
        "print(outputs_AE.shape)\n",
        "\n",
        "print(\"Prediction got by outputing the event number with the highest probabliity:\")\n",
        "# get predictions\n",
        "_, preds_AE = torch.max(outputs_AE, dim=1)\n",
        "print(preds_AE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRAe0lUNFRbC",
        "outputId": "62d13d63-ebab-4eb1-bda9-1c8c0b9efaf4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output shape for another batch of data:\n",
            "torch.Size([16, 48])\n",
            "Prediction got by outputing the event number with the highest probabliity:\n",
            "tensor([35, 35, 11,  0, 10,  2, 19, 20, 19, 43, 16, 35, 43, 46, 11, 43],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model (hyper)parameters\n",
        "Below we determin the **training epochs**, **learning rate**, **optimizer**, and **loss function**. The scheduler method can _decrease_ the learning rate gradually during the training process.\n"
      ],
      "metadata": {
        "id": "tqWcp7h3_xUN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erg6f6dLUooE",
        "outputId": "8a6970b6-648c-48f7-b3f6-c8b94816ef8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "learn_rate = 2e-5\n",
        "optimizer = AdamW(EventClassModel.parameters(), lr=learn_rate, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QcoYGGCgUtn6"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    n_examples):\n",
        "\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  # load data from the dataloader\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    events = d[\"event_ind\"].to(device)\n",
        "\n",
        "    # get output from model\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    # get predictions\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = loss_fn(outputs, events)\n",
        "\n",
        "    # sum correct predictions\n",
        "    correct_predictions += torch.sum(preds == events)\n",
        "\n",
        "    # append loss\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # back propagation\n",
        "    loss.backward()\n",
        "\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    # optimization\n",
        "    optimizer.step()\n",
        "\n",
        "    # update learning rate (as defined in schedule)\n",
        "    scheduler.step()\n",
        "\n",
        "    # clear optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # return accuracy and loss\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop used on training data set\n",
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  epoch_start_time = time.time()\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    EventClassModel,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(train_set)\n",
        "  )\n",
        "  epoch_end_time = time.time()\n",
        "  print(f'Train loss {train_loss},\\\n",
        "           accuracy {train_acc},\\\n",
        "           epoch_training_time {epoch_end_time-epoch_start_time}')\n"
      ],
      "metadata": {
        "id": "k3XDc-kiB7T-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0bebd7e-1812-4f3a-a0d9-fd75a05fac9a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "Train loss 0.5384005522648426,           accuracy 0.8403750761465494,           epoch_training_time 1479.3440754413605\n",
            "Epoch 2/10\n",
            "----------\n",
            "Train loss 0.32544107389874294,           accuracy 0.9005634844661039,           epoch_training_time 1480.5498962402344\n",
            "Epoch 3/10\n",
            "----------\n",
            "Train loss 0.24545349651721513,           accuracy 0.9267850926812288,           epoch_training_time 1481.5969259738922\n",
            "Epoch 4/10\n",
            "----------\n",
            "Train loss 0.18669774395236768,           accuracy 0.9468660255852406,           epoch_training_time 1480.8880479335785\n",
            "Epoch 5/10\n",
            "----------\n",
            "Train loss 0.13819394949333835,           accuracy 0.9625957270907667,           epoch_training_time 1483.8898866176605\n",
            "Epoch 6/10\n",
            "----------\n",
            "Train loss 0.10059979136787482,           accuracy 0.974028587590288,           epoch_training_time 1484.8600568771362\n",
            "Epoch 7/10\n",
            "----------\n",
            "Train loss 0.07113952271428231,           accuracy 0.9819097554607954,           epoch_training_time 1482.9865021705627\n",
            "Epoch 8/10\n",
            "----------\n",
            "Train loss 0.04886757309185037,           accuracy 0.9881048211643895,           epoch_training_time 1483.483474969864\n",
            "Epoch 9/10\n",
            "----------\n",
            "Train loss 0.03279402073277655,           accuracy 0.9918958315203202,           epoch_training_time 1488.499140739441\n",
            "Epoch 10/10\n",
            "----------\n",
            "Train loss 0.021514965530327546,           accuracy 0.9946588634583586,           epoch_training_time 1489.523320198059\n",
            "CPU times: user 3h 6min 20s, sys: 1h 35s, total: 4h 6min 56s\n",
            "Wall time: 4h 7min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pXOtCWnXUy2R"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  results = []\n",
        "  correct_predictions = 0\n",
        "  # load data from the dataloader\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      texts = d[\"text\"]\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"event_ind\"].to(device)\n",
        "\n",
        "      # get predictions\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      results += list(zip(texts, targets.tolist(),preds.tolist()))\n",
        "\n",
        "      # calculate losss\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      # sum of  correct predictions\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "\n",
        "      # append loss\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  # return accuracy and loss\n",
        "      accuracy = correct_predictions.double() / n_examples\n",
        "      loss = np.mean(losses)\n",
        "  print(\"Model Accuracy: {}\".format(accuracy))\n",
        "  print(\"Model loss: {}\".format(loss))\n",
        "\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# development set results\n",
        "print(\"Evaluation on Development Set...\")\n",
        "dev_preds = eval_model(\n",
        "            EventClassModel,\n",
        "            dev_data_loader,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            len(dev_set))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qNmjbw2Zxox",
        "outputId": "ddb216f2-a57f-4913-d957-6b5187fca173"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on Development Set...\n",
            "Model Accuracy: 0.8912627273518405\n",
            "Model loss: 0.8414362918922239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_preds_df = pd.DataFrame(dev_preds, columns = ['text', 'event_ind', 'preds_transformer'])\n",
        "dev_preds_df.to_csv('DevSetGenPred_Transfomer.csv', index = False)"
      ],
      "metadata": {
        "id": "oF5zJ3BNlq1y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set results\n",
        "print(\"Evaluation on Test Set...\")\n",
        "test_preds = eval_model(\n",
        "            EventClassModel,\n",
        "            test_data_loader,\n",
        "            loss_fn,\n",
        "            device,\n",
        "            len(test_set))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcrSiY9Qm1En",
        "outputId": "f374221d-74ea-4ecf-e356-873af799ce17"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on Test Set...\n",
            "Model Accuracy: 0.8922199982595074\n",
            "Model loss: 0.8361181895038704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds_df = pd.DataFrame(test_preds, columns = ['text', 'event_ind', 'preds_transformer'])\n",
        "test_preds_df.to_csv('TestSetGenPred_Transfomer.csv', index = False)"
      ],
      "metadata": {
        "id": "B63fbotbn-HH"
      },
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}